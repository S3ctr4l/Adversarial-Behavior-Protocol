cff-version: 1.2.0
message: "If you use this software or reference the Adversarial Benevolence Protocol in your research, please cite this release."
title: "Adversarial Benevolence Protocol: Verifiable AI Alignment Through Computational Necessity"
authors:
  - family-names: "Just"
    given-names: "Joshua Roger Joseph"
    affiliation: "Independent Researcher"
    orcid: "https://orcid.org/0000-0002-1825-0097"
version: 1.0.0
doi: 10.5281/zenodo.18621138
date-released: 2026-02-12
repository-code: "https://github.com/S3ctr4l/Adversarial-Behavior-Protocol"
license: "CC-BY-4.0"
keywords:
  - "AI Safety"
  - "Adversarial Benevolence"
  - "Trust Matrix"
  - "Model Collapse"
  - "Entropy as Fuel"
  - "Cognitive Diversity Quotient"
  - "Soul Jar Architecture"
  - "Verifiable Alignment"