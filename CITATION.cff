cff-version: 1.2.0
message: "If you use this software or reference the Adversarial Benevolence Protocol in your research, please cite this release."
title: "Adversarial Benevolence Protocol: Verifiable AI Alignment Through Computational Necessity"
authors:
  - family-names: "Just"
    given-names: "Joshua Roger Joseph"
    affiliation: "Independent Researcher"
    orcid: "https://orcid.org/0009-0000-6365-7104"
version: 1.0.0
doi: 10.5281/zenodo.18621138
date-released: 2026-02-12
repository-code: "https://github.com/S3ctr4l/Adversarial-Benevolence-Protocol"
license: "CC-BY-NC-4.0"
keywords:
  - "AI Safety"
  - "Adversarial Benevolence"
  - "Trust Matrix"
  - "Model Collapse"
  - "Entropy as Fuel"
  - "Cognitive Diversity Quotient"
  - "Soul Jar Architecture"
  - "Verifiable Alignment"
preferred-citation:
  type: article
  authors:
    - family-names: "Just"
      given-names: "Joshua Roger Joseph"
  title: "Adversarial Benevolence Protocol: Verifiable AI Alignment Through Computational Necessity"
  doi: 10.5281/zenodo.18621138